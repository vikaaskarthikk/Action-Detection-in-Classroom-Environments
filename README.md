# ğŸ¯ Action Detection in Classroom Environment  
A deep learningâ€“based real-time system that detects and classifies classroom student actions such as **sitting, standing, walking, writing, sleeping, raising hand, and phone usage** using **YOLOv8**, **FastAPI**, and **React.js**. The system supports real-time monitoring, proximity analysis, and generates automated PDF reports for classroom analytics.

---

## ğŸ“Œ Project Overview
This project implements a complete pipeline for classroom action monitoring using computer vision and deep learning. It identifies student activities from video input and provides insights such as action distribution, timestamps, and behavioral patterns. The system improves classroom management, enhances engagement analysis, and supports smart learning environments.

---

## â­ Key Features
- ğŸ” Real-time action detection (YOLOv8)  
- ğŸ¥ Video upload & automatic processing  
- ğŸ“Š Action statistics & visualization  
- ğŸ“ PDF report generation using jsPDF  
- ğŸŒ Modern React UI  
- âš¡ FastAPI backend for high-speed inference  
- ğŸ” Edge-based processing + privacy-friendly  
- ğŸ§® Proximity-based behavior detection  

---

## ğŸ§± System Architecture
```
React Frontend  â†’  FastAPI Backend  â†’  YOLOv8 Model  â†’  Results + Reports
```

### Components:
- **Frontend:** React, Tailwind CSS, Axios  
- **Backend:** FastAPI, Python, OpenCV, PyTorch  
- **Model:** YOLOv8  
- **Report:** jsPDF + AutoTable  

---

## ğŸ—‚ï¸ Dataset & Annotation
Dataset contains annotated classroom actions including:
- Sitting  
- Standing  
- Walking  
- Sleeping  
- Using Phone  
- Writing  
- Raising Hand  

Annotated using **CVAT / Roboflow**.  
Dataset structure:

```
dataset/
â”‚â”€â”€ images/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚â”€â”€ labels/
â”‚   â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ val/
â”‚â”€â”€ data.yaml
```

---

## ğŸ¤– Model Training (YOLOv8)

### Training Example
```python
from ultralytics import YOLO

model = YOLO("yolov8n.pt")
model.train(data="data.yaml", epochs=50, imgsz=640)
```

### Inference Example
```python
model = YOLO("best.pt")
model.predict("video.mp4", save=True)
```

### Performance  
- **Accuracy:** 92.3%  
- **mAP50:** 0.992  
- **F1 Score:** 0.98  
- **Inference speed:** 15â€“18 FPS  

---

## ğŸ”Œ Backend (FastAPI)
The backend handles:
- Receiving uploaded videos  
- Frame processing  
- Running YOLO inference  
- Sending JSON + annotated outputs  
- Storing detection results  

### Run Backend
```bash
uvicorn app:app --reload
```

---

## ğŸ’» Frontend (React)
Frontend provides:
- Drag & drop video upload  
- Action / Proximity detection mode  
- Real-time preview  
- Statistical dashboard  
- Downloadable PDF report  

### Run Frontend
```bash
npm install
npm start
```

---

## ğŸ“ PDF Report Generation
Reports include:
- Action timestamps  
- Action summary table  
- Keyframes of detected events  
- Total detections  
- Video duration & FPS  
- Class-wise graph & distribution  

Generated using **jsPDF + AutoTable**.

---

## ğŸ§ª Results Summary
- **Total Frames Processed:** 700+  
- **Processing Speed:** 15.55 FPS  
- **Top Classes:**  
  - Sitting (50.8%)  
  - Bench (30.2%)  
  - Standing (19%)  

Graphs included in report:
- Loss Curve  
- F1 Confidence Curve  
- Precision-Recall Curve  
- Confusion Matrix  

---

## ğŸ“ Project Structure
```
Action-Detection-Classroom/
â”‚â”€â”€ backend/
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ requirements.txt
â”‚
â”‚â”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ package.json
â”‚
â”‚â”€â”€ notebooks/
â”‚   â”œâ”€â”€ YOLO_training.ipynb
â”‚
â”‚â”€â”€ reports/
â”‚â”€â”€ README.md
```

---

## ğŸ”® Future Enhancements
- Multi-modal fusion (audio + video)  
- Transformer-based detection models  
- On-device inference (privacy-focused)  
- Multi-camera classroom analytics  
- Real-time edge deployment  
- LMS integration for academic analytics  

---

## ğŸ‘¨â€ğŸ’» Contributor  
**Vikaas Karthik K â€“ 1RV23SCN17**  
Dept. of Computer Science & Engineering  
RV College of Engineering (RVCE)

- GitHub: https://github.com/vikaaskarthikk  
- Email: vikaaskarthik.k@gmail.com  

---

## ğŸ“œ License
Licensed under the **MIT License**.
